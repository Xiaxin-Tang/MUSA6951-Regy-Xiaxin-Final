{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOFAHF9IQ35aeoBMebLlCo9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yvoxz4nE2pUt","executionInfo":{"status":"ok","timestamp":1746398675917,"user_tz":240,"elapsed":6194,"user":{"displayName":"Xiaxin Tang","userId":"09551191718524994649"}},"outputId":"6fbd2200-a795-4c44-dbe1-ab3581a27b45"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Total images in dataset: 19442\n","Using 1458 images (7.50% of dataset)\n","Train: 1020, Val: 218, Test: 220\n","Batch shape: torch.Size([32, 3, 128, 128]), Labels: torch.Size([32])\n"]}],"source":["# 1. Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 2. Install PyTorch (if not already)\n","!pip install torch torchvision --quiet\n","\n","# 3. Imports\n","import torch\n","from torchvision import transforms, datasets\n","from torch.utils.data import DataLoader, Subset, random_split\n","import random\n","\n","# 4. Set dataset root\n","root = \"/content/drive/MyDrive/Colab Notebooks/data/naip_patches\"\n","\n","# 5. Image transformations\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Resize((128, 128)),  # Resize to 128x128\n","    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)  # Normalize to [-1, 1]\n","])\n","\n","# 6. Load dataset\n","dataset = datasets.ImageFolder(root=root, transform=transform)\n","total = len(dataset)\n","print(f\"Total images in dataset: {total}\")\n","\n","# 7. Randomly sample 1.5% of the dataset\n","subset_size = int(0.075 * total)\n","indices = list(range(total))\n","random.shuffle(indices)\n","subset_indices = indices[:subset_size]\n","subset = Subset(dataset, subset_indices)\n","print(f\"Using {subset_size} images ({100*subset_size/total:.2f}% of dataset)\")\n","\n","# 8. Split into train/val/test (70/15/15)\n","train_size = int(0.7 * subset_size)\n","val_size = int(0.15 * subset_size)\n","test_size = subset_size - train_size - val_size\n","train_set, val_set, test_set = random_split(subset, [train_size, val_size, test_size])\n","print(f\"Train: {len(train_set)}, Val: {len(val_set)}, Test: {len(test_set)}\")\n","\n","# 9. DataLoaders\n","train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_set, batch_size=32)\n","test_loader = DataLoader(test_set, batch_size=32)\n","\n","# 10. Print a batch shape for sanity check\n","images, labels = next(iter(train_loader))\n","print(f\"Batch shape: {images.shape}, Labels: {labels.shape}\")\n"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","\n","# Use pretrained ResNet18\n","model = models.resnet18(pretrained=True)\n","model.fc = nn.Linear(model.fc.in_features, 4)  # 4 ridership classes\n","\n","model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"jpQ8-4xn2tZ-","executionInfo":{"status":"ok","timestamp":1746398680728,"user_tz":240,"elapsed":850,"user":{"displayName":"Xiaxin Tang","userId":"09551191718524994649"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","\n","for epoch in range(10):  # adjust as needed\n","    model.train()\n","    running_loss = 0.0\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mzFeGX9C2pxW","executionInfo":{"status":"ok","timestamp":1746399839669,"user_tz":240,"elapsed":1156854,"user":{"displayName":"Xiaxin Tang","userId":"09551191718524994649"}},"outputId":"b03e9d6a-53bb-4171-f399-5444e03b6aac"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.9126\n","Epoch 2, Loss: 0.3017\n","Epoch 3, Loss: 0.1665\n","Epoch 4, Loss: 0.0668\n","Epoch 5, Loss: 0.0368\n","Epoch 6, Loss: 0.0293\n","Epoch 7, Loss: 0.0215\n","Epoch 8, Loss: 0.0133\n","Epoch 9, Loss: 0.0137\n","Epoch 10, Loss: 0.0078\n"]}]},{"cell_type":"code","source":["import torch\n","\n","def evaluate_model(model, dataloader, device):\n","    model.eval()  # Set model to evaluation mode\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():  # No need to track gradients\n","        for images, labels in dataloader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs, 1)  # Get class with highest score\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = 100 * correct / total\n","    return accuracy\n","\n","# Usage example:\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)  # Make sure your model is on the right device\n","\n","test_accuracy = evaluate_model(model, test_loader, device)\n","print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mcxrUE5ieDnp","executionInfo":{"status":"ok","timestamp":1746399913621,"user_tz":240,"elapsed":21946,"user":{"displayName":"Xiaxin Tang","userId":"09551191718524994649"}},"outputId":"7dbc4c05-2279-40a8-c9f0-452443a1d587"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 80.45%\n"]}]}]}